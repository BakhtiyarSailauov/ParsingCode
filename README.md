Здраствуйте, меня зовут Бахтияр. Я студент 3-курса. Недавно я начал активно изучать Python. 
И в целях обучение написал этот проект для парсинга. В проекте использваны техналогии, такие
как BeautifulSoup и requests. Для парсинга используется сайт: https://scrapingclub.com

Само сабой использвание проекта пользователем не сложная, и все аспекты четко обьясняется для
правильного использование. 

С помощью этого кода, вы сможете получить данные про все котологи в сайте. А если конкретно,
название продукта, цена, описание, и ссылку на сайт. Парсинг работаем очень быстро, и локанично.

Для подробности обясню весь процесс шаг за шагом:

Шаг 1:
      Когда запускаем проект, в консоли выйдет полная описание что от пользовотеля. И сразу после 
      этого от пользователя запрашиваем ссылку на сайт для наглядности.
Шаг 2: 
      Надо указать с какой страницы начинаем парсит. Имется ввиду не ссылка, а целостное 
      число, для указание страницу.
Шаг 3:
      Точно так же укажем конечную страницу. Примичание: если указать больше страниц, чем есть
      на сайте, то данные сохранится сразу, и код закроется.
Шаг 4: 
      Надо указать сколько секунд мы будем задерживать парсинг, что-бы избежать 
      исключение от сайта, для защиты.
Шаг 5: 
      Запрашиваем от пользователя путь для сохранение Exsel файла. Надо учесть, что когда указываем путь,
      конечная папка, это название Exsel файла. И чтобы избежать исключение, надо указать не существующую 
      папку. Так как у нас нету права, чтобы перезаписать файл.
Шаг 6:
      Пользовател укажет путь, чтобы сохранить скачанные файлы. Тут без ограничений, как в преведущем шаге.
Шаг 7:
      Процесс запустился! Теперь надо просто ждать.

В заключение: Этот проект мой второй софт который я сам написал на Python. Так что прошу не судить строго.
 
